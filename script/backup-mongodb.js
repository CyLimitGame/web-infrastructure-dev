#!/usr/bin/env node

/**
 * OBJECTIF : Script de sauvegarde compl√®te de la base de donn√©es MongoDB CyLimit
 * 
 * POURQUOI : Permet de cr√©er des backups complets de la base de donn√©es avant toute
 * op√©ration risqu√©e (migrations, suppressions, etc.). Conforme √† la r√®gle absolue
 * de toujours faire un backup avant toute op√©ration destructive.
 * 
 * COMMENT :
 * 1. Parse l'URL MongoDB fournie pour extraire les informations de connexion
 * 2. Cr√©e un r√©pertoire de backup avec timestamp unique
 * 3. Ex√©cute mongodump avec retry automatique et gestion d'erreurs robuste
 * 4. Sauvegarde collection par collection pour √©viter la perte totale en cas d'erreur
 * 5. V√©rifie l'int√©grit√© du backup cr√©√©
 * 6. Affiche la taille et le chemin du backup
 * 7. Optionnellement compresse le backup en archive tar.gz
 * 
 * Appel√© depuis : Ligne de commande manuelle ou autres scripts de migration
 * D√©pendances : mongodump (MongoDB Database Tools) doit √™tre install√© sur le syst√®me
 */

const { execSync, exec, spawn } = require('child_process');
const { promisify } = require('util');
const fs = require('fs');
const path = require('path');

const execAsync = promisify(exec);

// URL MongoDB fournie
// NOTE: Assurez-vous que le nom de la base de donn√©es dans l'URI est correct (cylimit, pas test)
const MONGODB_URI = 'mongodb+srv://cylimit2:rundeal974@cylimit.en0by.mongodb.net/cylimit?authSource=admin&replicaSet=atlas-v3fgec-shard-0&readPreference=primary&ssl=true';
//const MONGODB_URI_DEV = 'mongodb://root:123456@localhost:27444/cylimit_dev?authSource=admin';

// Options de ligne de commande
const args = process.argv.slice(2);
const shouldCompress = args.includes('--compress') || args.includes('-c');
const outputDir = args.find(arg => arg.startsWith('--output='))?.split('=')[1] || null;
const retryCount = parseInt(args.find(arg => arg.startsWith('--retry='))?.split('=')[1] || '3');
const resumeBackup = args.find(arg => arg.startsWith('--resume='))?.split('=')[1] || null;
const collectionOnly = args.find(arg => arg.startsWith('--collection='))?.split('=')[1] || null;
const help = args.includes('--help') || args.includes('-h');

if (help) {
  console.log(`
üì¶ Script de Backup MongoDB - CyLimit

Usage:
  node script/backup-mongodb.js [options]

Options:
  --compress, -c          Compresse le backup en archive tar.gz
  --output=<dir>         Sp√©cifie le r√©pertoire de sortie (d√©faut: ./backups/)
  --retry=<n>            Nombre de tentatives en cas d'erreur (d√©faut: 3)
  --resume=<backupDir>   Reprend un backup partiel existant
  --collection=<name>    Sauvegarde uniquement une collection sp√©cifique
  --help, -h             Affiche cette aide

Exemples:
  node script/backup-mongodb.js
  node script/backup-mongodb.js --compress
  node script/backup-mongodb.js --output=/path/to/backups --compress
  node script/backup-mongodb.js --retry=5
  node script/backup-mongodb.js --resume=./backups/cylimit-backup-2025-11-20T03-56-53
  node script/backup-mongodb.js --collection=game_teams

‚ö†Ô∏è  IMPORTANT: Assurez-vous que mongodump est install√© sur votre syst√®me.
   Installation: https://www.mongodb.com/try/download/database-tools
  `);
  process.exit(0);
}

/**
 * Obtient la liste des collections de la base de donn√©es
 * Utilise mongodump avec --dryRun pour lister les collections sans les sauvegarder
 * 
 * @param {string} uri - URI de connexion MongoDB
 * @returns {Promise<string[]>} Liste des noms de collections
 */
async function getCollections(uri) {
  try {
    // Essayer d'abord avec mongosh si disponible
    try {
      const command = `mongosh "${uri}" --quiet --eval "db.getCollectionNames().join('\\n')"`;
      const { stdout } = await execAsync(command, { timeout: 10000 });
      const collections = stdout.trim().split('\n').filter(name => name.length > 0 && !name.includes('MongoServerError'));
      if (collections.length > 0) {
        return collections;
      }
    } catch (mongoshError) {
      // mongosh n'est pas disponible, on continue avec mongodump
    }
    
    // Fallback: utiliser mongodump avec --dryRun pour lister les collections
    // Note: mongodump ne supporte pas --dryRun, donc on utilise une autre approche
    // On va simplement essayer de sauvegarder toutes les collections et laisser
    // mongodump g√©rer les erreurs pour les collections inexistantes
    return null; // Retourner null pour utiliser le backup complet
  } catch (error) {
    console.warn('‚ö†Ô∏è  Impossible de lister les collections, utilisation du backup complet');
    return null;
  }
}

/**
 * V√©rifie si une collection est d√©j√† sauvegard√©e
 * 
 * @param {string} backupDir - R√©pertoire de backup
 * @param {string} collectionName - Nom de la collection
 * @param {string} dbName - Nom de la base de donn√©es
 * @returns {boolean} True si la collection existe d√©j√†
 */
function isCollectionBackedUp(backupDir, collectionName, dbName = 'cylimit') {
  const dbBackupPath = path.join(backupDir, dbName);
  const bsonFile = path.join(dbBackupPath, `${collectionName}.bson`);
  const metadataFile = path.join(dbBackupPath, `${collectionName}.metadata.json`);
  
  return fs.existsSync(bsonFile) && fs.existsSync(metadataFile);
}

/**
 * Sauvegarde une collection sp√©cifique avec retry
 * 
 * @param {string} uri - URI de connexion MongoDB
 * @param {string} backupDir - R√©pertoire de backup
 * @param {string} collectionName - Nom de la collection
 * @param {number} maxRetries - Nombre maximum de tentatives
 * @returns {Promise<void>}
 */
async function backupCollection(uri, backupDir, collectionName, maxRetries = 3) {
  let lastError = null;
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      if (attempt > 1) {
        console.log(`   üîÑ Tentative ${attempt}/${maxRetries} pour ${collectionName}...`);
        // Attendre avant de r√©essayer (backoff exponentiel)
        await new Promise(resolve => setTimeout(resolve, Math.min(1000 * Math.pow(2, attempt - 2), 10000)));
      }
      
      const dbName = extractDatabaseName(uri);
      const command = `mongodump --uri="${uri}" --db=${dbName} --collection="${collectionName}" --out="${backupDir}" --numParallelCollections=1`;
      
      // Utiliser spawn pour afficher les logs en temps r√©el
      return new Promise((resolve, reject) => {
        // Construire les arguments directement sans parser la commande
        // Cela √©vite les probl√®mes de parsing avec les caract√®res sp√©ciaux dans l'URI
        const args = [
          '--uri', uri,
          '--db', dbName,
          '--collection', collectionName,
          '--out', backupDir,
          '--numParallelCollections', '1'
        ];
        
        const mongodump = spawn('mongodump', args, {
          stdio: ['ignore', 'pipe', 'pipe'],
          shell: false
        });
        
        let lastProgressTime = Date.now();
        
        // mongodump √©crit ses logs sur stderr, pas stdout !
        mongodump.stderr.on('data', (data) => {
          const output = data.toString();
          const lines = output.split('\n').filter(line => line.trim());
          
          lines.forEach(line => {
            if (line.includes('writing')) {
              console.log(`   üì¶ ${collectionName}: D√©but de la sauvegarde...`);
              lastProgressTime = Date.now();
            } else if (line.includes('done dumping')) {
              const match = line.match(/done dumping\s+(\S+)\s+\((\d+)\s+documents\)/);
              if (match) {
                const docCount = parseInt(match[2]).toLocaleString();
                console.log(`   üìä ${collectionName}: ${docCount} documents trait√©s`);
              }
            } else if (line.includes('[') && line.includes('%')) {
              const match = line.match(/(\[.*?\])\s+(\S+)\s+(\d+)\/(\d+)\s+\(([\d.]+)%\)/);
              if (match) {
                const current = parseInt(match[3]);
                const total = parseInt(match[4]);
                const percent = parseFloat(match[5]);
                const currentFormatted = current.toLocaleString();
                const totalFormatted = total.toLocaleString();
                
                // Afficher toutes les 2 secondes
                const now = Date.now();
                if (now - lastProgressTime > 2000 || percent >= 100) {
                  console.log(`   üìä ${collectionName}: ${currentFormatted}/${totalFormatted} (${percent.toFixed(1)}%)`);
                  lastProgressTime = now;
                }
              }
            } else if (line.includes('error') || line.includes('Error') || line.includes('Failed')) {
              console.error(`   ‚ö†Ô∏è  ${line}`);
            }
          });
        });
        
        // stdout peut contenir des informations aussi
        mongodump.stdout.on('data', (data) => {
          const output = data.toString();
          if (output.trim()) {
            console.log(`   ‚ÑπÔ∏è  ${output.trim()}`);
          }
        });
        
        mongodump.on('close', async (code) => {
          if (code === 0) {
            // V√©rifier que le fichier a √©t√© cr√©√©
            const dbBackupPath = path.join(backupDir, dbName);
            const bsonFile = path.join(dbBackupPath, `${collectionName}.bson`);
            
            if (fs.existsSync(bsonFile)) {
              const stats = fs.statSync(bsonFile);
              const sizeMB = (stats.size / (1024 * 1024)).toFixed(2);
              console.log(`   ‚úÖ ${collectionName}: ${sizeMB} MB`);
              resolve(); // Succ√®s
            } else {
              reject(new Error(`Fichier ${bsonFile} non cr√©√©`));
            }
          } else {
            reject(new Error(`mongodump s'est termin√© avec le code ${code}`));
          }
        });
        
        mongodump.on('error', (error) => {
          reject(error);
        });
      });
    } catch (error) {
      lastError = error;
      const errorMsg = error.message || error.stderr || String(error);
      
      // Si c'est une erreur de connexion, on r√©essaye
      if (errorMsg.includes('connection reset') || 
          errorMsg.includes('connection closed') ||
          errorMsg.includes('incomplete read') ||
          errorMsg.includes('timeout')) {
        if (attempt < maxRetries) {
          console.log(`   ‚ö†Ô∏è  Erreur de connexion pour ${collectionName}, nouvelle tentative...`);
          continue;
        }
      }
      
      // Pour les autres erreurs, on arr√™te
      throw error;
    }
  }
  
  throw lastError || new Error(`√âchec apr√®s ${maxRetries} tentatives pour ${collectionName}`);
}

/**
 * Cr√©e un backup complet de la base de donn√©es MongoDB avec gestion d'erreurs robuste
 * 
 * @param {string} uri - URI de connexion MongoDB compl√®te
 * @param {string} backupDir - R√©pertoire de destination du backup
 * @param {number} maxRetries - Nombre de tentatives en cas d'erreur
 * @param {string[]} collectionsToSkip - Collections d√©j√† sauvegard√©es √† ignorer
 * @returns {Promise<string>} Chemin du r√©pertoire de backup cr√©√©
 */
async function createBackup(uri, backupDir, maxRetries = 3, collectionsToSkip = []) {
  const dbName = extractDatabaseName(uri);
  
  console.log('üíæ Cr√©ation du backup MongoDB...');
  console.log(`üìÅ R√©pertoire: ${backupDir}`);
  console.log(`üîó Base de donn√©es: ${dbName}`);
  console.log(`üîÑ Tentatives max par collection: ${maxRetries}`);
  
  // Cr√©er le r√©pertoire de backup s'il n'existe pas
  if (!fs.existsSync(backupDir)) {
    fs.mkdirSync(backupDir, { recursive: true });
  }
  
  const dbBackupPath = path.join(backupDir, dbName);
  if (!fs.existsSync(dbBackupPath)) {
    fs.mkdirSync(dbBackupPath, { recursive: true });
  }
  
  // Si une seule collection est demand√©e
  if (collectionOnly) {
    console.log(`üì¶ Sauvegarde de la collection: ${collectionOnly}`);
    await backupCollection(uri, backupDir, collectionOnly, maxRetries);
  } else {
    // Obtenir la liste des collections
    console.log('üìã R√©cup√©ration de la liste des collections...');
    let collections = await getCollections(uri);
    
    if (!collections || collections.length === 0) {
      // Fallback: utiliser mongodump complet avec retry
      console.log('‚è≥ Ex√©cution de mongodump complet (toutes collections)...');
      await backupWithRetry(uri, backupDir, maxRetries);
    } else {
      // Sauvegarder collection par collection
      console.log(`üìä ${collections.length} collections trouv√©es\n`);
      
      const skipped = [];
      const failed = [];
      const succeeded = [];
      
      for (const collection of collections) {
        // Ignorer les collections d√©j√† sauvegard√©es
        if (collectionsToSkip.includes(collection) || isCollectionBackedUp(backupDir, collection, dbName)) {
          skipped.push(collection);
          console.log(`   ‚è≠Ô∏è  ${collection}: d√©j√† sauvegard√©e`);
          continue;
        }
        
        try {
          await backupCollection(uri, backupDir, collection, maxRetries);
          succeeded.push(collection);
        } catch (error) {
          failed.push({ collection, error: error.message });
          console.error(`   ‚ùå ${collection}: ${error.message}`);
        }
      }
      
      // R√©sum√©
      console.log(`\nüìä R√©sum√© du backup:`);
      console.log(`   ‚úÖ R√©ussies: ${succeeded.length}`);
      console.log(`   ‚è≠Ô∏è  Ignor√©es: ${skipped.length}`);
      console.log(`   ‚ùå √âchou√©es: ${failed.length}`);
      
      if (failed.length > 0) {
        console.log(`\n‚ö†Ô∏è  Collections en √©chec:`);
        failed.forEach(({ collection, error }) => {
          console.log(`   - ${collection}: ${error}`);
        });
        throw new Error(`${failed.length} collection(s) n'ont pas pu √™tre sauvegard√©es`);
      }
    }
  }
  
  // V√©rifier que le backup existe et afficher les statistiques
  // dbBackupPath est d√©j√† d√©fini plus haut dans la fonction
  
  if (fs.existsSync(dbBackupPath)) {
    const collections = fs.readdirSync(dbBackupPath).filter(file => {
      const filePath = path.join(dbBackupPath, file);
      return fs.statSync(filePath).isFile() && file.endsWith('.bson');
    });
    
    if (collections.length === 0) {
      throw new Error(`Aucune collection sauvegard√©e dans ${dbBackupPath}. V√©rifiez que la base de donn√©es "${dbName}" existe et contient des collections.`);
    }
    
    console.log(`\n‚úÖ Backup cr√©√© avec succ√®s !`);
    console.log(`üìä Collections sauvegard√©es: ${collections.length}`);
    
    let totalSize = 0;
    collections.forEach(collection => {
      const collectionPath = path.join(dbBackupPath, collection);
      const stats = fs.statSync(collectionPath);
      totalSize += stats.size;
      const sizeMB = (stats.size / (1024 * 1024)).toFixed(2);
      console.log(`   - ${collection.replace('.bson', '')}: ${sizeMB} MB`);
    });
    
    // Afficher la taille totale
    try {
      const totalSizeStr = execSync(`du -sh "${backupDir}"`, { encoding: 'utf8' }).trim();
      console.log(`üì¶ Taille totale: ${totalSizeStr}`);
    } catch (error) {
      const totalSizeMB = (totalSize / (1024 * 1024)).toFixed(2);
      console.log(`üì¶ Taille totale: ${totalSizeMB} MB`);
    }
    
    return backupDir;
  } else {
    throw new Error(`Backup cr√©√© mais r√©pertoire non trouv√©: ${dbBackupPath}. V√©rifiez que la base de donn√©es "${dbName}" existe dans l'URI MongoDB.`);
  }
}

/**
 * Extrait le nom de la base de donn√©es de l'URI MongoDB
 * 
 * @param {string} uri - URI MongoDB
 * @returns {string} Nom de la base de donn√©es
 */
function extractDatabaseName(uri) {
  try {
    // Format: mongodb://host/dbname ou mongodb+srv://host/dbname
    const match = uri.match(/\/([^/?]+)(\?|$)/);
    if (match && match[1]) {
      return match[1];
    }
    // Fallback: utiliser 'cylimit' par d√©faut
    return 'cylimit';
  } catch (error) {
    return 'cylimit';
  }
}

/**
 * Backup complet avec retry (fallback si la liste des collections √©choue)
 */
async function backupWithRetry(uri, backupDir, maxRetries = 3) {
  let lastError = null;
  const dbName = extractDatabaseName(uri);
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      if (attempt > 1) {
        console.log(`üîÑ Tentative ${attempt}/${maxRetries}...`);
        await new Promise(resolve => setTimeout(resolve, 2000 * attempt));
      }
      
      const command = `mongodump --uri="${uri}" --out="${backupDir}" --numParallelCollections=1`;
      
      console.log(`   Ex√©cution: mongodump pour la base "${dbName}"...`);
      console.log(`   ‚è≥ Veuillez patienter, cela peut prendre plusieurs minutes...\n`);
      
      // Utiliser spawn pour afficher les logs en temps r√©el
      return new Promise((resolve, reject) => {
        // Construire les arguments directement sans parser la commande
        // Cela √©vite les probl√®mes de parsing avec les caract√®res sp√©ciaux dans l'URI
        const args = [
          '--uri', uri,
          '--out', backupDir,
          '--numParallelCollections', '1'
        ];
        
        const mongodump = spawn('mongodump', args, {
          stdio: ['ignore', 'pipe', 'pipe'],
          shell: false
        });
        
        let lastProgressTime = Date.now();
        let lastCollection = '';
        let collectionsProcessed = new Set();
        
        // mongodump √©crit ses logs sur stderr, pas stdout !
        mongodump.stderr.on('data', (data) => {
          const output = data.toString();
          const lines = output.split('\n').filter(line => line.trim());
          
          lines.forEach(line => {
            // Filtrer et formater les messages de progression
            if (line.includes('writing')) {
              const match = line.match(/writing\s+(\S+)\s+to/);
              if (match && match[1] !== lastCollection) {
                lastCollection = match[1];
                const collectionName = match[1].split('.').pop();
                if (!collectionsProcessed.has(collectionName)) {
                  console.log(`\n   üì¶ Sauvegarde de la collection: ${collectionName}...`);
                  collectionsProcessed.add(collectionName);
                  lastProgressTime = Date.now();
                }
              }
            } else if (line.includes('done dumping')) {
              const match = line.match(/done dumping\s+(\S+)\s+\((\d+)\s+documents\)/);
              if (match) {
                const collectionName = match[1].split('.').pop();
                const docCount = parseInt(match[2]).toLocaleString();
                console.log(`   ‚úÖ ${collectionName}: ${docCount} documents sauvegard√©s`);
              }
            } else if (line.includes('[') && line.includes('%')) {
              // Barre de progression
              const match = line.match(/(\[.*?\])\s+(\S+)\s+(\d+)\/(\d+)\s+\(([\d.]+)%\)/);
              if (match) {
                const collectionName = match[2].split('.').pop();
                const current = parseInt(match[3]);
                const total = parseInt(match[4]);
                const percent = parseFloat(match[5]);
                const currentFormatted = current.toLocaleString();
                const totalFormatted = total.toLocaleString();
                
                // Afficher seulement toutes les 3 secondes pour √©viter le spam
                const now = Date.now();
                if (now - lastProgressTime > 3000 || percent >= 100) {
                  console.log(`   üìä ${collectionName}: ${currentFormatted}/${totalFormatted} (${percent.toFixed(1)}%)`);
                  lastProgressTime = now;
                }
              }
            } else if (line.includes('error') || line.includes('Error') || line.includes('Failed')) {
              console.error(`   ‚ö†Ô∏è  ${line}`);
            }
          });
        });
        
        // stdout peut contenir des informations aussi
        mongodump.stdout.on('data', (data) => {
          const output = data.toString();
          if (output.trim()) {
            console.log(`   ‚ÑπÔ∏è  ${output.trim()}`);
          }
        });
        
        mongodump.on('close', (code) => {
          if (code === 0) {
            resolve();
          } else {
            reject(new Error(`mongodump s'est termin√© avec le code ${code}`));
          }
        });
        
        mongodump.on('error', (error) => {
          reject(error);
        });
      });
      
      // V√©rifier que des fichiers ont √©t√© cr√©√©s
      const dbBackupPath = path.join(backupDir, dbName);
      if (!fs.existsSync(dbBackupPath)) {
        throw new Error(`Le r√©pertoire de backup n'a pas √©t√© cr√©√©: ${dbBackupPath}. V√©rifiez que la base de donn√©es "${dbName}" existe et contient des collections.`);
      }
      
      const files = fs.readdirSync(dbBackupPath).filter(f => f.endsWith('.bson'));
      if (files.length === 0) {
        throw new Error(`Aucune collection sauvegard√©e. V√©rifiez que la base de donn√©es "${dbName}" existe et contient des collections.`);
      }
      
      console.log(`   ‚úÖ ${files.length} collection(s) sauvegard√©e(s)`);
      return; // Succ√®s
    } catch (error) {
      lastError = error;
      const errorMsg = error.message || error.stderr || String(error);
      
      // Afficher l'erreur pour debug
      if (attempt === 1) {
        console.error(`   ‚ùå Erreur: ${errorMsg.substring(0, 200)}...`);
      }
      
      if (errorMsg.includes('connection reset') || 
          errorMsg.includes('connection closed') ||
          errorMsg.includes('incomplete read') ||
          errorMsg.includes('timeout')) {
        if (attempt < maxRetries) {
          continue;
        }
      }
      
      // Si c'est une erreur de base de donn√©es inexistante, ne pas r√©essayer
      if (errorMsg.includes('not found') || 
          errorMsg.includes('does not exist') ||
          errorMsg.includes('authentication failed')) {
        throw error;
      }
      
      if (attempt < maxRetries) {
        continue;
      }
      
      throw error;
    }
  }
  
  throw lastError || new Error(`√âchec apr√®s ${maxRetries} tentatives`);
}

/**
 * Calcule la taille d'un r√©pertoire de mani√®re r√©cursive (fallback pour Windows)
 */
function calculateDirectorySize(dirPath) {
  let totalSize = 0;
  
  function calculateSize(currentPath) {
    const stats = fs.statSync(currentPath);
    
    if (stats.isFile()) {
      totalSize += stats.size;
    } else if (stats.isDirectory()) {
      const files = fs.readdirSync(currentPath);
      files.forEach(file => {
        calculateSize(path.join(currentPath, file));
      });
    }
  }
  
  calculateSize(dirPath);
  return totalSize;
}

/**
 * Compresse le backup en archive tar.gz
 * 
 * @param {string} backupDir - R√©pertoire √† compresser
 * @returns {Promise<string>} Chemin de l'archive cr√©√©e
 */
async function compressBackup(backupDir) {
  return new Promise((resolve, reject) => {
    try {
      const archivePath = `${backupDir}.tar.gz`;
      console.log(`\nüóúÔ∏è  Compression du backup...`);
      console.log(`üì¶ Archive: ${archivePath}`);
      
      // Cr√©er l'archive tar.gz
      const dirName = path.basename(backupDir);
      const parentDir = path.dirname(backupDir);
      
      execSync(`cd "${parentDir}" && tar -czf "${path.basename(archivePath)}" "${dirName}"`, {
        stdio: 'inherit',
        encoding: 'utf8'
      });
      
      // Afficher la taille de l'archive
      const stats = fs.statSync(archivePath);
      const sizeMB = (stats.size / (1024 * 1024)).toFixed(2);
      console.log(`‚úÖ Archive cr√©√©e: ${sizeMB} MB`);
      
      resolve(archivePath);
    } catch (error) {
      console.error('‚ùå Erreur lors de la compression:', error.message);
      reject(error);
    }
  });
}

/**
 * Obtient les collections d√©j√† sauvegard√©es dans un backup existant
 */
function getBackedUpCollections(backupDir, dbName = 'cylimit') {
  const dbBackupPath = path.join(backupDir, dbName);
  if (!fs.existsSync(dbBackupPath)) {
    return [];
  }
  
  return fs.readdirSync(dbBackupPath)
    .filter(file => file.endsWith('.bson'))
    .map(file => file.replace('.bson', ''));
}

/**
 * Fonction principale
 */
async function main() {
  let backupDir = null; // D√©clarer en dehors du try pour √™tre accessible dans le catch
  
  try {
    let collectionsToSkip = [];
    
    // Si on reprend un backup existant
    if (resumeBackup) {
      if (!fs.existsSync(resumeBackup)) {
        throw new Error(`Le r√©pertoire de backup sp√©cifi√© n'existe pas: ${resumeBackup}`);
      }
      backupDir = resumeBackup;
      const dbName = extractDatabaseName(MONGODB_URI);
      collectionsToSkip = getBackedUpCollections(backupDir, dbName);
      console.log(`üîÑ Reprise du backup existant: ${backupDir}`);
      console.log(`üìã Collections d√©j√† sauvegard√©es: ${collectionsToSkip.length}`);
      if (collectionsToSkip.length > 0) {
        console.log(`   ${collectionsToSkip.slice(0, 5).join(', ')}${collectionsToSkip.length > 5 ? '...' : ''}`);
      }
    } else {
      // Cr√©er le nom du r√©pertoire de backup avec timestamp
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, 19);
      const baseBackupDir = outputDir || path.join(process.cwd(), 'backups');
      backupDir = path.join(baseBackupDir, `cylimit-backup-${timestamp}`);
    }
    
    // Cr√©er le backup
    await createBackup(MONGODB_URI, backupDir, retryCount, collectionsToSkip);
    
    // Compresser si demand√©
    if (shouldCompress) {
      await compressBackup(backupDir);
      console.log(`\nüéâ Backup compress√© disponible: ${backupDir}.tar.gz`);
    } else {
      console.log(`\nüéâ Backup disponible: ${backupDir}`);
    }
    
    console.log(`\nüí° Pour restaurer ce backup, utilisez:`);
    console.log(`   mongorestore --uri="<URI>" "${backupDir}"`);
    
    // Si le backup √©tait partiel, sugg√©rer de reprendre
    if (resumeBackup && collectionsToSkip.length > 0) {
      console.log(`\nüí° Pour reprendre ce backup, utilisez:`);
      console.log(`   node script/backup-mongodb.js --resume="${backupDir}"`);
    }
    
  } catch (error) {
    console.error('\n‚ùå √âchec du backup:', error.message);
    
    // Si le backup √©tait partiel, sugg√©rer de reprendre
    if (!resumeBackup && backupDir && fs.existsSync(backupDir)) {
      const dbName = extractDatabaseName(MONGODB_URI);
      const backedUp = getBackedUpCollections(backupDir, dbName);
      if (backedUp.length > 0) {
        console.log(`\nüí° ${backedUp.length} collection(s) ont √©t√© sauvegard√©es avant l'erreur.`);
        console.log(`   Pour reprendre le backup, utilisez:`);
        console.log(`   node script/backup-mongodb.js --resume="${backupDir}"`);
      }
    }
    
    process.exit(1);
  }
}

// Ex√©cuter le script
main();

