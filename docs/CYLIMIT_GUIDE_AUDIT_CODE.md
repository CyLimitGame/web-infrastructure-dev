# CyLimit - Guide d'Audit Code et Setup Local

## üéØ OBJECTIF : Comprendre et Optimiser SANS RISQUE

Vous avez raison d'√™tre prudent ! On va analyser le code en d√©tail pour comprendre ce qui consomme vraiment avant de faire des changements.

---

## üöÄ √âTAPE 1 : Setup Environnement Local (30 minutes)

### **1.1 Pr√©requis**
```bash
# V√©rifiez que vous avez :
- Docker & Docker Compose
- Node.js 16+ 
- Yarn
- Git

# V√©rification :
docker --version
node --version
yarn --version
```

### **1.2 Cr√©er docker-compose.local.yml**
```yaml
# Cr√©ez ce fichier dans cylimit-backend-develop/
version: '3.9'

services:
  mongodb-local:
    image: mongo:6.0
    container_name: cylimit-mongodb-local
    ports:
      - "27017:27017"
    volumes:
      - mongodb_local_data:/data/db
    environment:
      - MONGO_INITDB_DATABASE=cylimit_dev
    command: mongod --wiredTigerCacheSizeGB 0.5

  redis-local:
    image: redis:alpine
    container_name: cylimit-redis-local
    ports:
      - "6379:6379"
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru

volumes:
  mongodb_local_data:
```

### **1.3 Cr√©er .env.local**
```bash
# Cr√©ez .env.local dans cylimit-backend-develop/
NODE_ENV=development
PORT=4000
BASE_URL=http://localhost:4000/v1

# MongoDB Local
MONGODB_HOST=localhost
MONGODB_PORT=27017
MONGODB_DATABASE=cylimit_dev
MONGODB_USER=
MONGODB_PASSWORD=

# Redis Local  
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# JWT (utilisez des cl√©s de dev)
JWT_SECRET=dev_secret_key_123
JWT_ADMIN_SECRET=dev_admin_secret_456

# AWS (d√©sactiv√© en local)
AWS_ACCESS_KEY_ID=disabled
AWS_SECRET_ACCESS_KEY=disabled
AWS_REGION=eu-west-3
AWS_PUBLIC_BUCKET_NAME=disabled

# Autres services (d√©sactiv√©s)
STRIPE_SECRET_KEY=sk_test_disabled
MAILCHIMP_API_KEY=disabled
```

### **1.4 Lancer l'Environnement Local**
```bash
# Dans cylimit-backend-develop/
docker-compose -f docker-compose.local.yml up -d

# V√©rifier que √ßa marche :
docker ps
# Vous devriez voir mongodb-local et redis-local running
```

### **1.5 Installer & Lancer Backend**
```bash
# Dans cylimit-backend-develop/
yarn install
yarn dev

# Si √ßa marche, vous verrez :
# "Nest application successfully started on port 4000"
```

---

## üîç √âTAPE 2 : Audit des Collections MongoDB (15 minutes)

### **2.1 Connecter √† MongoDB Local**
```bash
# Avec MongoDB Compass (GUI) :
mongodb://localhost:27017/cylimit_dev

# Ou en ligne de commande :
docker exec -it cylimit-mongodb-local mongosh cylimit_dev
```

### **2.2 Analyser les Collections Cr√©√©es**
```javascript
// Dans mongosh :
show collections

// Pour chaque collection, v√©rifiez la structure :
db.users.findOne()
db.nfts.findOne()
db.address_activities.findOne()
db.payment_transactions.findOne()

// Comptez les documents :
db.users.countDocuments()
db.nfts.countDocuments()
// etc.
```

### **2.3 Identifier les Collections "Logs"**
```javascript
// Collections suspectes (probablement volumineuses en prod) :
db.address_activities.findOne()    // Events blockchain
db.payment_transactions.findOne()  // Logs paiements
db.xp_transactions.findOne()      // Historique XP
db.nft_sales.findOne()            // Historique ventes
db.game_rewards.findOne()         // Historique r√©compenses

// Questions √† se poser :
// - Cette collection grandit-elle ind√©finiment ?
// - A-t-on besoin de garder tout l'historique ?
// - Peut-on mettre un TTL ?
```

---

## üõ†Ô∏è √âTAPE 3 : Audit des T√¢ches Cron (20 minutes)

### **3.1 Analyser le Fichier Principal**
```bash
# Ouvrez : src/cron-job/cron-job.service.ts
# Listez toutes les t√¢ches et leur fr√©quence :

EVERY_MINUTE:
- autoClaimWinningNftAuctions()
- fetchExchangeRates()

EVERY_15_MINUTES:  
- calculateGameRanking()

EVERY_HOUR:
- syncRidersOnComingGames()

DAILY:
- calculateAverageCapScores()
- claimAllWaitingReferredRewards()
- notifyFavoriteNftAuction()
```

### **3.2 Questions pour Chaque T√¢che**
```bash
# Pour chaque t√¢che cron, demandez-vous :

1. autoClaimWinningNftAuctions() - EVERY_MINUTE
   - Combien d'ench√®res avez-vous par jour ?
   - Besoin vraiment de v√©rifier chaque minute ?
   - Peut passer √† EVERY_10_MINUTES ?

2. fetchExchangeRates() - EVERY_MINUTE  
   - Les taux changent-ils si souvent ?
   - EVERY_HOUR suffisant ?

3. calculateGameRanking() - EVERY_15_MINUTES
   - Pendant les heures creuses (nuit), n√©cessaire ?
   - Peut √™tre conditionnel selon l'activit√© ?
```

### **3.3 Estimer l'Impact CPU**
```bash
# Dans les logs de votre app locale :
# Regardez combien de temps prend chaque t√¢che
# Calculez : fr√©quence √ó temps = charge CPU

# Exemple :
# calculateGameRanking() prend 2 secondes
# Toutes les 15 minutes = 4 fois/heure
# = 8 secondes CPU/heure pour cette t√¢che seule
```

---

## üìä √âTAPE 4 : Audit des Mod√®les de Donn√©es (25 minutes)

### **4.1 Analyser les Sch√©mas Volumineux**
```bash
# Ouvrez ces fichiers et analysez :

src/modules/nft/schemas/nft.schema.ts
- Combien de champs ?
- Lesquels sont optionnels/inutiles ?
- Index redondants ?

src/modules/user/schemas/user.schema.ts  
- Donn√©es personnelles stock√©es inutilement ?
- Champs calcul√©s qui pourraient √™tre dynamiques ?

src/modules/game/schemas/game.schema.ts
- R√©sultats stock√©s en dur vs calcul√©s √† la demande ?
```

### **4.2 Identifier les Timestamps Inutiles**
```bash
# Cherchez dans tous les sch√©mas :
grep -r "timestamps.*true" src/modules/*/schemas/

# Pour chaque fichier trouv√©, demandez-vous :
# - A-t-on vraiment besoin de createdAt/updatedAt ?
# - Pour l'audit ? Pour l'affichage ? Pour les requ√™tes ?
# - Peut-on s'en passer ?

# √âconomie potentielle : 16 bytes √ó nombre de documents
```

### **4.3 Analyser les Relations**
```bash
# Regardez les r√©f√©rences entre collections :
# - Y a-t-il des donn√©es dupliqu√©es ?
# - Des jointures co√ªteuses ?
# - Des donn√©es d√©normalis√©es inutiles ?

# Exemple dans nft.schema.ts :
@Prop({ type: Types.ObjectId, ref: 'UserEntity' })
public ownerId!: Types.ObjectId;

# Question : Stocke-t-on aussi des infos user dans le NFT ?
```

---

## üéØ √âTAPE 5 : Cr√©er votre Plan d'Optimisation (15 minutes)

### **5.1 Template de Rapport**
```markdown
# Mon Audit CyLimit - [Date]

## Collections Volumineuses Identifi√©es :
1. [nom_collection] - [taille estim√©e] - [utilit√©]
2. [nom_collection] - [taille estim√©e] - [utilit√©]

## T√¢ches Cron Sur-fr√©quentes :
1. [nom_t√¢che] - [fr√©quence actuelle] ‚Üí [fr√©quence propos√©e]
2. [nom_t√¢che] - [fr√©quence actuelle] ‚Üí [fr√©quence propos√©e]

## Timestamps Inutiles :
1. [collection] - [justification suppression]
2. [collection] - [justification suppression]

## √âconomies Estim√©es :
- R√©duction taille MongoDB : -X%
- R√©duction charge CPU : -Y%  
- √âconomies co√ªts : -Z$/mois
```

### **5.2 Priorisation des Actions**
```bash
# Classez vos optimisations par :
1. Impact √©conomique (√©conomie $/mois)
2. Facilit√© d'impl√©mentation (heures de dev)
3. Risque (faible/moyen/√©lev√©)

# Commencez par : Impact √©lev√© + Facilit√© √©lev√©e + Risque faible
```

---

## üõ†Ô∏è OUTILS d'ANALYSE Recommand√©s

### **MongoDB Analysis**
```bash
# Dans mongosh, utilisez ces commandes :

# Taille par collection :
db.runCommand("dbStats")
db.stats()

# Top collections par taille :
db.runCommand("listCollections").cursor.firstBatch.forEach(
  function(collection) {
    print(collection.name + ": " + db[collection.name].stats().size + " bytes");
  }
);

# Index analysis :
db.collection_name.getIndexes()
db.collection_name.totalIndexSize()
```

### **Code Analysis Tools**
```bash
# Recherches utiles dans le code :

# Trouve toutes les op√©rations de cr√©ation/update :
grep -r "\.save()\|\.create()\|\.insertMany()" src/

# Trouve les timestamps :
grep -r "timestamps.*true" src/

# Trouve les TTL existants :
grep -r "expireAfterSeconds" src/

# Trouve les t√¢ches lourdes :
grep -r "forEach\|map\|filter" src/ | grep -v node_modules
```

---

## üìã CHECKLIST de D√©marrage

### **Aujourd'hui (1 heure) :**
- [ ] Setup environnement local (docker-compose + .env)
- [ ] Lancer backend en local  
- [ ] Connecter √† MongoDB local
- [ ] Lister les collections cr√©√©es

### **Demain (2 heures) :**
- [ ] Audit complet des t√¢ches cron
- [ ] Identifier les 3 collections les plus suspectes
- [ ] Cr√©er votre premier rapport d'audit
- [ ] Prioriser 3 optimisations faciles

### **Cette Semaine :**
- [ ] Impl√©menter la premi√®re optimisation (la plus simple)
- [ ] Tester en local
- [ ] Mesurer l'impact
- [ ] Documenter pour application en prod

---

## ‚ùì QUESTIONS pour Vous Guider

### **Pendant l'Audit, Demandez-vous :**
1. **Cette donn√©e est-elle vraiment n√©cessaire ?**
2. **Combien de temps doit-on la garder ?**
3. **Cette t√¢che doit-elle tourner si souvent ?**
4. **Peut-on calculer √ßa √† la demande plut√¥t que de stocker ?**
5. **Cette fonctionnalit√© est-elle utilis√©e par nos 200 users ?**

### **Pour Prioriser :**
1. **Quel est l'impact sur la taille MongoDB ?**
2. **Combien √ßa √©conomise en $/mois ?**
3. **Combien de temps pour impl√©menter ?**
4. **Quel est le risque de casser quelque chose ?**

---

## üéØ OBJECTIF Final

**√Ä la fin de cet audit, vous devriez avoir :**
- Une compr√©hension claire de ce qui consomme dans votre code
- 5-10 optimisations concr√®tes √† impl√©menter  
- Un plan d'√©conomies chiffr√© (X$/mois)
- Une roadmap d'impl√©mentation sans risque

**Commencez-vous par le setup local ? C'est la base pour tout comprendre !**